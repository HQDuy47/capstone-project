input {
	jdbc {
		jdbc_connection_string => "jdbc:postgresql://192.168.1.12:5432/capstone"
		jdbc_user => "postgres"
		jdbc_password => "localdb"
		jdbc_driver_library => "/usr/share/logstash/vendor/postgresql-42.6.1.jar"
		jdbc_driver_class => "org.postgresql.Driver"
		statement => "SELECT * from job"
		schedule => "* * * * *" # every minute
  	}
	kafka{
		# codec => json
        bootstrap_servers => "192.168.1.12:9092"
		auto_offset_reset => "earliest"
        topics => ["es-topic"]
    }
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => ["elasticsearch:9200"]
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "es-index"
	}
	elasticsearch {
		hosts => ["elasticsearch:9200"]
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "jobsdata"
		document_id => "%{id}"
	}
}
